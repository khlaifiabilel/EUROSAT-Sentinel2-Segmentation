{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7762ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Image Classifier Pytorch Model\n",
    "    \"\"\"\n",
    "    # pylint: disable=no-member\n",
    "    # pylint: disable=not-callable\n",
    "\n",
    "    __default_config__ = {\n",
    "        \"input_size\": 64,\n",
    "        \"labels\": ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'],\n",
    "        \"loss_function\": \"crossentropy\",\n",
    "        'dropout': 0.2,\n",
    "\n",
    "    }\n",
    "\n",
    "    def __init__(self, config: Dict = None):\n",
    "        \"\"\"\n",
    "        Image Classifier\n",
    "\n",
    "        Args:\n",
    "            config (Dict): Configurations that contains the following keys: input_size, labels\n",
    "        \"\"\"\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.config = self.__default_config__ if config is None else config\n",
    "\n",
    "        self.labels = list(self.config[\"labels\"])\n",
    "        self.num_classes = len(self.labels)\n",
    "\n",
    "        if self.config['loss_function'] == 'crossentropy':\n",
    "            self.loss_fcn = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise ValueError('Unknown criterion')\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3, 3),\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3, 3),\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                int(((self.config[\"input_size\"] - 5 + 1) // 2)) ** 2 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.config['dropout']),\n",
    "            nn.Linear(128, self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes output Tensors from input Tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Input Tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output Tensors.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.backbone(inputs)\n",
    "\n",
    "    def predict(self, inputs: np.ndarray) -> List[str]:\n",
    "        \"\"\"\n",
    "        Converts logits to predictions.\n",
    "\n",
    "        Args:\n",
    "            inputs (np.ndarray): Input Data.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Returns a list of predicted labels.\n",
    "        \"\"\"\n",
    "        data = self.preprocess_input(inputs)\n",
    "        preds = torch.softmax(self.backbone(data), axis=-1)\n",
    "\n",
    "        outputs = []\n",
    "        for scores in preds.detach().cpu().numpy().tolist():\n",
    "            output = {label: round(score, 3) for score,\n",
    "                      label in zip(scores, self.labels)}\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_path: str, *args, **kwargs) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Load model from a pre-trained model.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Pretrained model path.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: Pretrained model.\n",
    "        \"\"\"\n",
    "        state_dict = torch.load(model_path)\n",
    "        pretrained_model = cls(config=state_dict['config'], *args, **kwargs)\n",
    "        pretrained_model.load_state_dict(state_dict['state_dict'])\n",
    "        return pretrained_model\n",
    "\n",
    "    @classmethod\n",
    "    def summarize(cls, input_size=(3, 64, 64)):\n",
    "        \"\"\"\n",
    "        Summarizes torch model by showing trainable parameters and weights.\n",
    "\n",
    "        Args:\n",
    "            input_size (tuple, optional): Input size of the model. Defaults to (3, 64, 64).\n",
    "\n",
    "        Returns:\n",
    "            Summary of the model.\n",
    "        \"\"\"\n",
    "\n",
    "        return torchsummary.summary(cls().to(device), input_size=input_size)\n",
    "\n",
    "    def to(self, device: str, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Performs Tensor device conversion.\n",
    "\n",
    "        Args:\n",
    "            device (str): Device to convert to.\n",
    "\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        return super().to(device, *args, **kwargs)\n",
    "\n",
    "    def preprocess_input(self, input_array: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Preprocesses input array to be compatible with the model.\n",
    "\n",
    "        Args:\n",
    "            input_array (np.ndarray): Input array.\n",
    "\n",
    "        Raises:\n",
    "            AssertionError: If input_array is not a shape of (h,w,c) or (bs,h,w,c).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Converted input array as torch.Tensor.\n",
    "        \"\"\"\n",
    "        data = input_array.copy()\n",
    "\n",
    "        if len(data.shape) == 3:  # h,w,c\n",
    "            new_inputs = torch.from_numpy(\n",
    "                np.expand_dims(data, axis=0)).float().permute(0, 3, 1, 2).contiguous()\n",
    "        elif len(data.shape) == 4:  # assumed bs,h,w,c\n",
    "            new_inputs = torch.from_numpy(\n",
    "                data).float().permute(0, 3, 1, 2).contiguous()\n",
    "        else:\n",
    "            raise AssertionError(\n",
    "                f\"input shape not supported: {data.shape}\")\n",
    "        return new_inputs.to(self.device)\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Loss function.\n",
    "\n",
    "        Args:\n",
    "            y_pred : Predicted output.\n",
    "            y_true : True output.\n",
    "\n",
    "        Returns:\n",
    "                Loss value.\n",
    "        \"\"\"\n",
    "        return self.loss_fcn(y_pred, y_true)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Classifier().to(device)\n",
    "\n",
    "    input_array = np.random.rand(64, 64, 3)\n",
    "    result = model.predict(input_array)\n",
    "    print(result)\n",
    "\n",
    "    # input_tensor = torch.randn(1, 3, 64, 64).to(device)\n",
    "    # forward = model(input_tensor)  # pylint: disable=not-callable\n",
    "    # print(forward)\n",
    "\n",
    "    # from cv2 import cv2\n",
    "    # input_img = cv2.imread('data/EuroSAT/2750/AnnualCrop/AnnualCrop_12.jpg')\n",
    "    # input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # result = model.predict(input_img)\n",
    "    # print(result)\n",
    "\n",
    "    # print(model.summarize())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
