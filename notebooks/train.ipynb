{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "\n",
    "# import torch.nn.init\n",
    "from colorama import Fore\n",
    "from dataset import EurosatDataset\n",
    "from model import Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ed53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Object for parsing command line strings into Python objects.\n",
    "    \"\"\"\n",
    "    arg = argparse.ArgumentParser()\n",
    "\n",
    "    arg.add_argument(\"--epoch\", type=int, default=10)\n",
    "    arg.add_argument(\n",
    "        \"--device\", type=int, default=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), choices=['cuda', 'cpu'])\n",
    "    arg.add_argument(\"--save_dir\", type=str, default=\"./saved_models\")\n",
    "    arg.add_argument(\"--data_dir\", type=str, default=\"data/EuroSAT/\")\n",
    "\n",
    "    arg.add_argument(\"--batch_size\", type=int, default=128,\n",
    "                     help=\"total number of batch size of labeled data\")\n",
    "\n",
    "    arg.add_argument(\"--eval_batch_size\", type=int, default=256,\n",
    "                     help=\"batch size of evaluation data loader\")\n",
    "\n",
    "    arg.add_argument(\"--criterion\", type=str,\n",
    "                     default=\"crossentropy\", choices=['crossentropy'])\n",
    "    arg.add_argument(\"--optimizer\", type=str,\n",
    "                     default=\"sgd\", choices=['sgd', 'adam'])\n",
    "\n",
    "    arg.add_argument(\"--learning_rate\", type=float, default=0.01)\n",
    "    arg.add_argument(\"--momentum\", type=float, default=0.9)\n",
    "    arg.add_argument(\"--weight_decay\", type=float, default=5e-4)\n",
    "    arg.add_argument(\"--dropout\", type=float, default=0.0,\n",
    "                     choices=[0.0, 0.5, 0.7, 0.9, 0.99, 0.999])\n",
    "    arg.add_argument(\"--num_workers\", type=int, default=3)\n",
    "    arg.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    return arg.parse_args()\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Sofmax function.\n",
    "    \"\"\"\n",
    "    return np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "\n",
    "def accuracy(gt_S, pred_S):\n",
    "    \"\"\"\n",
    "    Get the accuracy of the model.\n",
    "\n",
    "    Args:\n",
    "        gt_S : Ground truth.\n",
    "        pred_S : Prediction.\n",
    "\n",
    "    Returns:\n",
    "        Accuracy classification score.\n",
    "    \"\"\"\n",
    "    _, alp = torch.max(torch.from_numpy(pred_S), 1)\n",
    "    return accuracy_score(gt_S, np.asarray(alp))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Image Classification Model Training.\n",
    "    \"\"\"\n",
    "    # pylint: disable=not-callable\n",
    "\n",
    "    # Seed for reproducibility\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "\n",
    "    writer = SummaryWriter(\n",
    "        comment=f\"Learn_{args.learning_rate}_Drop{args.dropout}\")\n",
    "\n",
    "    # Construct Dataset\n",
    "\n",
    "    train_dataset = EurosatDataset(\n",
    "        is_train=True, seed=args.seed, root_dir=args.data_dir)\n",
    "\n",
    "    print(\n",
    "        f'Number of data on Train Dataset is {len(train_dataset)}')\n",
    "\n",
    "    test_dataset = EurosatDataset(\n",
    "        is_train=False, seed=args.seed, root_dir=args.data_dir)\n",
    "\n",
    "    print(\n",
    "        f'Number of data on Test Dataset is {len(test_dataset)}')\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.eval_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f'The images split in train and test is based on the seed {args.seed}')\n",
    "\n",
    "    config = {\n",
    "        \"input_size\": train_dataset.size[0],\n",
    "        \"labels\": train_dataset.label_encoding,\n",
    "        \"loss_function\": args.criterion,\n",
    "        'dropout': args.dropout,\n",
    "    }\n",
    "    model = Classifier(config=config)\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    if args.optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate,\n",
    "                               weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.learning_rate,\n",
    "                              momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        raise ValueError('Unknown optimizer')\n",
    "\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    test_acc = []\n",
    "    train_acc = []\n",
    "\n",
    "    best_acc = 0\n",
    "    correct_pred = {classname: 0 for classname in train_dataset.label_encoding}\n",
    "    total_pred = {classname: 0 for classname in train_dataset.label_encoding}\n",
    "\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Start training with {args.epoch} epochs')\n",
    "\n",
    "    for e in range(1, args.epoch + 1):\n",
    "        with tqdm(train_loader, unit=\"batch\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET)) as train_epoch:\n",
    "            model.train()\n",
    "            for data, target in train_epoch:\n",
    "                # get the inputs; train_epoch is a list of [data, target]\n",
    "                data, target = (\n",
    "                    Variable(data.to(args.device)),\n",
    "                    Variable(target.to(args.device)),\n",
    "                )\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                output = model(data)\n",
    "                loss = model.loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses = np.append(train_losses, loss.item())\n",
    "                pred = output.data.cpu().numpy()  # [0]\n",
    "                pred = softmax(pred)\n",
    "                gt = target.data.cpu().numpy()  # [0]\n",
    "                train_acc = np.append(train_acc, accuracy(gt, pred))\n",
    "\n",
    "                train_epoch.set_description(f\"Epoch {e}\")\n",
    "                train_epoch.set_postfix(\n",
    "                    loss=loss.item(), acc=train_acc[-1], mean_loss=np.mean(train_losses), mean_acc=np.mean(train_acc))\n",
    "\n",
    "            writer.add_scalar('Loss/train', np.mean(train_losses), e)\n",
    "            writer.add_scalar('Accuracy/train', np.mean(train_acc), e)\n",
    "\n",
    "        with tqdm(test_loader, unit=\"batch\", bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.RED, Fore.RESET)) as test_epoch:\n",
    "            model.eval()\n",
    "            # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_epoch:\n",
    "                    data, target = (\n",
    "                        Variable(data.to(args.device)),\n",
    "                        Variable(target.to(args.device)),\n",
    "                    )\n",
    "\n",
    "                    # calculate outputs by running images through the network\n",
    "                    output = model(data)\n",
    "                    loss = model.loss(output, target)\n",
    "                    test_losses = np.append(test_losses, loss.item())\n",
    "\n",
    "                    # the class with the highest conf is what we choose as prediction\n",
    "                    _, pred = torch.max(output, 1)\n",
    "\n",
    "                    for label, prediction in zip(target, pred):\n",
    "                        if label == prediction:\n",
    "                            correct_pred[train_dataset.label_encoding[\n",
    "                                label]] += 1\n",
    "                        total_pred[train_dataset.label_encoding[label]] += 1\n",
    "\n",
    "                    pred = output.data.cpu().numpy()  # [0]\n",
    "                    pred = softmax(pred)\n",
    "                    gt = target.data.cpu().numpy()  # [0]\n",
    "                    test_acc = np.append(test_acc, accuracy(gt, pred))\n",
    "\n",
    "                    test_epoch.set_description(f\"Test\")\n",
    "                    test_epoch.set_postfix(\n",
    "                        loss=loss.item(), acc=test_acc[-1], mean_loss=np.mean(test_losses), mean_acc=np.mean(test_acc))\n",
    "\n",
    "            writer.add_scalar('Loss/test', np.mean(test_losses), e)\n",
    "            writer.add_scalar('Accuracy/test', np.mean(test_acc), e)\n",
    "            state = {\n",
    "                'config': config,\n",
    "                'state_dict': model.state_dict(),\n",
    "            }\n",
    "            if np.mean(test_acc) > best_acc:\n",
    "                best_acc = np.mean(test_acc)\n",
    "                torch.save(state,\n",
    "                           f\"{args.save_dir}/model_best.pth\")\n",
    "\n",
    "            torch.save(state,\n",
    "                       f\"{args.save_dir}/model_epoch{e}_acc{round(np.mean(test_acc),2)}.pth\")\n",
    "            for classname, correct_count in correct_pred.items():\n",
    "                t_accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "                # print(f'Accuracy for class: {classname:5s} is {t_accuracy:.1f} %')\n",
    "                writer.add_scalar(f\"Accuracy/{classname}\", t_accuracy, e)\n",
    "\n",
    "    print('Finished Training')\n",
    "    print(f'Saving the model on {args.save_dir}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_arguments()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
