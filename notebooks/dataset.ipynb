{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "\n",
    "import os \n",
    "import imageio \n",
    "\n",
    "import torch \n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "from skimage import img_as_float32, img_as_ubyte\n",
    "from skimage.transform import resize \n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "from colorama import Fore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EUROSAT Sentinel2 discription :\n",
    "# Land use  and land cover classification using Sentinel2 Sat images. \n",
    "# EUROSAT dataset  is used for deep learning benchmark for land use and land cover classification\n",
    "# Based on Sentinel2 sat images, EUROSAT cover 13 spactral band and consist of 10 classes.\n",
    "# EUROSAT dataset has 27.000 labeled and geo-referenced images in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df600924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing \n",
    "\n",
    "class EurosatDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    EuroSAT: Land Use and Land Cover Classification with Sentinel-2\n",
    "    Eurosat is a dataset and deep learning benchmark for land use and land cover classification. The dataset is based on Sentinel-2 satellite images covering 13 spectral bands and consisting out of 10 classes with in total 27,000 labeled and geo-referenced images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_train, root_dir=\"data/EuroSAT/\", transform=None, seed=42, download=False):\n",
    "        \"\"\"\n",
    "        EurosatDataset\n",
    "\n",
    "        Args:\n",
    "            is_train (bool): If true returns training set, else test set.\n",
    "            root_dir (str, optional): Root directory of dataset. Defaults to \"data/EuroSAT/2750/\".\n",
    "            transform ([type], optional): Optional transform to be applied on a sample. Defaults to None.\n",
    "            seed (int, optional): Seed used for train/test split. Defaults to 42.\n",
    "            download (bool, optional): If True, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded it is not downloaded again. Defaults to False.\n",
    "        \"\"\"\n",
    "\n",
    "        self.seed = seed\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.download = download\n",
    "\n",
    "        self.size = [64, 64]\n",
    "        self.num_channels = 3\n",
    "        self.num_classes = 10\n",
    "        self.test_ratio = 0.2\n",
    "        self.N = 27000\n",
    "        self.extaraced = '2750'\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the data from the passed root directory. Splits in test/train based on seed.\n",
    "\n",
    "        Raises:\n",
    "            RuntimeError: It will raise when folder not exists.\n",
    "        \"\"\"\n",
    "\n",
    "        images = np.zeros(\n",
    "            [self.N, self.size[0], self.size[1], 3], dtype=\"uint8\")\n",
    "        labels = []\n",
    "        filenames = []\n",
    "\n",
    "        if self.download:\n",
    "            self.download_dataset()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found. You can use download=True to download it\"\n",
    "            )\n",
    "\n",
    "        i = 0\n",
    "        data_dir = os.path.join(self.root_dir, self.extaraced)\n",
    "\n",
    "        with tqdm(os.listdir(data_dir), bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.GREEN, Fore.RESET)) as dir_bar:\n",
    "            for item in dir_bar:\n",
    "                f = os.path.join(data_dir, item)\n",
    "                if os.path.isfile(f):\n",
    "                    continue\n",
    "                for subitem in os.listdir(f):\n",
    "                    sub_f = os.path.join(f, subitem)\n",
    "                    filenames.append(sub_f)\n",
    "\n",
    "                    # a few images are a few pixels off, we will resize them\n",
    "                    image = imageio.imread(sub_f)\n",
    "                    if image.shape[0] != self.size[0] or image.shape[1] != self.size[1]:\n",
    "                        # print(\"Resizing image...\")\n",
    "                        image = img_as_ubyte(\n",
    "                            resize(\n",
    "                                image, (self.size[0], self.size[1]), anti_aliasing=True)\n",
    "                        )\n",
    "                    images[i] = img_as_ubyte(image)\n",
    "                    i += 1\n",
    "                    labels.append(item)\n",
    "\n",
    "                dir_bar.set_description(\n",
    "                    f\"{'Train' if self.is_train else 'Test'} images are reading..\")\n",
    "                dir_bar.set_postfix(category=item)\n",
    "\n",
    "        labels = np.asarray(labels)\n",
    "        filenames = np.asarray(filenames)\n",
    "\n",
    "        # sort by filenames\n",
    "        images = images[filenames.argsort()]\n",
    "        labels = labels[filenames.argsort()]\n",
    "\n",
    "        # convert to integer labels\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        label_encoder.fit(np.sort(np.unique(labels)))\n",
    "        labels = label_encoder.transform(labels)\n",
    "        labels = np.asarray(labels)\n",
    "        # remember label encoding\n",
    "        self.label_encoding = list(label_encoder.classes_)\n",
    "\n",
    "        # split into a is_train and test set as provided data is not presplit\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            images,\n",
    "            labels,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.seed,\n",
    "            stratify=labels,\n",
    "        )\n",
    "\n",
    "        if self.is_train:\n",
    "            self.data = x_train\n",
    "            self.targets = y_train\n",
    "        else:\n",
    "            self.data = x_test\n",
    "            self.targets = y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = self.data[idx]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        # img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        image = np.asarray(img / 255, dtype=\"float32\")\n",
    "\n",
    "        return image.transpose(2, 0, 1), self.targets[idx]\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check the Root directory is exists\n",
    "        \"\"\"\n",
    "        return os.path.exists(self.root_dir)\n",
    "\n",
    "    def download_dataset(self) -> None:\n",
    "        \"\"\"\n",
    "        Download the dataset from the internet\n",
    "        \"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.root_dir, exist_ok=True)\n",
    "        download_and_extract_archive(\n",
    "            \"https://madm.dfki.de/files/sentinel/EuroSAT.zip\",\n",
    "            download_root=self.root_dir,\n",
    "            md5=\"c8fa014336c82ac7804f0398fcb19387\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08937c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dset = EurosatDataset(is_train=False, seed=42, download=True)\n",
    "    print(len(dset))\n",
    "    print(dset.label_encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
